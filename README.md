# AutoScrape - Automotive Data Engineering Pipeline

A comprehensive data engineering project for scraping, processing, and analyzing automotive marketplace data from 50 major US cities.

## ğŸ¯ Project Overview

AutoScrape implements a complete data lakehouse architecture for automotive market intelligence, following the Bronze â†’ Silver â†’ Gold data processing pattern.

## ğŸ—ï¸ Architecture

```
Phase 1: Data Extraction âœ…
â”œâ”€â”€ Web scraping from Craigslist (50 cities)
â”œâ”€â”€ Scheduled daily collection (Dagster)
â””â”€â”€ Raw CSV output

Phase 2: Data Lake Architecture âœ…  
â”œâ”€â”€ Bronze Layer: Raw data â†’ Parquet format
â”œâ”€â”€ Silver Layer: Cleaned, validated data
â””â”€â”€ Gold Layer: Aggregated city analytics

Phase 3: Analytics & BI (Next)
â”œâ”€â”€ Interactive dashboards
â”œâ”€â”€ Time series analysis
â””â”€â”€ Geographic insights
```

## ğŸ“Š Data Pipeline

**Extraction:**
- 50 major US cities
- Car listings (year, make, model, price, mileage)
- Owner/Dealer classification
- Geographic metadata

**Processing:**
- Data validation and cleaning
- Price standardization ($15,000 â†’ 15000)
- Mileage normalization (74k â†’ 74000)
- Duplicate removal

**Analytics:**
- City-level aggregations
- Market price analysis
- Inventory insights

## ğŸš€ Quick Start

### Prerequisites
```bash
pip install -r requirements.txt
```

### Run Data Pipeline

**1. Extract car data (50 cities):**
```bash
dagster job execute -f definitions.py -j car_scraping_pipeline
```

**2. Process data (Bronze â†’ Silver â†’ Gold):**
```bash
dagster job execute -f definitions.py -j data_processing_pipeline
```

**3. Set up daily automation:**
```bash
start_scheduler.bat
```

## ğŸ“ Project Structure

```
AutoScrape/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ pipelines/cars/cars/           # Data extraction
â”‚   â””â”€â”€ transformations/               # Data processing
â”œâ”€â”€ storage/                           # Data lake
â”‚   â”œâ”€â”€ bronze/                       # Raw data
â”‚   â”œâ”€â”€ silver/                       # Clean data
â”‚   â””â”€â”€ gold/                         # Analytics
â”œâ”€â”€ config/                           # Configuration
â””â”€â”€ requirements.txt                  # Dependencies
```

## ğŸ”§ Technologies

- **Orchestration:** Dagster
- **Data Processing:** Pandas, PyArrow
- **Storage:** Parquet (Columnar format)
- **Scraping:** BeautifulSoup, Requests
- **Infrastructure:** Python, CSV â†’ Parquet

## ğŸ“ˆ Expected Output

- **2,500-5,000+ car listings** per run
- **City-level analytics** (avg price, inventory count)
- **Clean, structured data** ready for ML/BI tools
- **Daily automated collection**

## ğŸ¯ Use Cases

- Automotive market research
- Price trend analysis
- Geographic market insights
- Inventory optimization
- Competitive intelligence

## ğŸ“‹ Status

- âœ… Phase 1: Data Extraction (Complete)
- âœ… Phase 2: Data Lake Architecture (Complete)  
- ğŸš§ Phase 3: Analytics & BI (In Progress)

## ğŸ”„ Data Flow

```
Raw CSV â†’ Bronze (Parquet) â†’ Silver (Clean) â†’ Gold (Analytics)
```

**Sample Output:**
```
City Analytics (Gold Layer):
- New York, NY: Avg $18,500, 250 listings
- Los Angeles, CA: Avg $16,200, 180 listings  
- Chicago, IL: Avg $15,800, 165 listings
```
